<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Introduction to My Blog</title>
    <url>/2021/04/13/blog-inro/</url>
    <content><![CDATA[<p>This is my blog, built at March, 2021, supported by Github &amp; Hexo &amp; NexT Theme.</p>
<p>Accumulation does matter.</p>
<p>This blog would serve as window, where I could share my my points, output fantastic ideas and trace any change inside my mind.</p>
<p>For Now, I would focus more on producing notes and posts from my leanrning, as many as possible.</p>
<p>I hope that what i will write or i have wrriten would make a difference to the world.</p>
]]></content>
      <tags>
        <tag>Introduction</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2022/05/24/design-for-testability/dft-2/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/05/13/design-for-testability/limfxinfo/</url>
    <content><![CDATA[{"articleId":"7c760bf9-c204-4400-9259-ee5dfd3782fb","cookie":"","baseUrl":"https://www.limfx.pro","mdName":"","keyvalPair":{"":"","standard-ieee-test-access-methods.md":"7c760bf9-c204-4400-9259-ee5dfd3782fb"},"keyvalstring":"{\"\":\"\",\"standard-ieee-test-access-methods.md\":\"7c760bf9-c204-4400-9259-ee5dfd3782fb\"}"}]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/02/07/design-for-testability/standard-ieee-test-access-methods/</url>
    <content><![CDATA[<hr>
<p>title: ‘Standard IEEE (1149.1) Test Access Methods’<br>date: 2022-02-07 16:45:02<br>tags: DFT </p>
<hr>
<!-- title: Standard IEEE (1149.1) Test Access Methods; -->
<!-- keywords: DFT; -->
<!-- description: Brief description of IEEE standard 1149.1 -->


<h2 id="0-overview"><a href="#0-overview" class="headerlink" title="0.overview"></a>0.overview</h2><p>为什么我们需要边界扫描：</p>
<ol>
<li><p>IP的集成（拼装）使得一个board上的互联（interconnect）变得极其复杂，互联也可能会产生错误，因尔除去IP内部的被测到，这些互联的错误也需要被测到，往往这些fault的激发（activation）会极其复杂，如果是从顶层角度，即ATE给激励，则会产生不可接受的测试cost。 </p>
</li>
<li><p>如果我们只想测试一块board中某一个core，core的输入来自某个core的输出，core的输出又要经过另一个core才到PO，那么从top level的角度来说，这个core的testability极低。因为激励的灌入和响应的收集极其困难。</p>
</li>
</ol>
<p>Test Access Methods 是不同于Scan扫描的一种方法，它的关注点和目标主要在CUT的边界，而扫描关注的往往是CUT内部的信号。这种方法我们也通常抽象成Boundary Scan 边界扫描。</p>
<p>边界扫描有两个特点：</p>
<ol>
<li><p>边界扫描的design不能影响到边界包围内core内部的正常工作。 </p>
</li>
<li><p>边界扫描的目的在于能独立一块board其他core，来测试一个core/CUT。边界扫描衍生出一套IEEE std. 1149.1, 这套协议常常被成为Boundary Scan 边界扫描。</p>
</li>
</ol>
<p>但是其实1149.1 协议本身除了边界扫描（通过边界寄存器）这个功能，还有一个功能为Debug Access（通过数据寄存器）。为了区分，下面用BS-1149.1 来简称这个协议，BS-1149.1 有自己的定义好的架构和硬件。它用指令（instructions）去控制CUT内部和外部的连接情况以达到独立于其他core单独测试（isolating testing）某块CUT的目的。</p>
<p>BS-1149.1 还定义了BSDL（Boundary Scan Description language）</p>
<hr>
<h2 id="1-边界扫描的基础："><a href="#1-边界扫描的基础：" class="headerlink" title="1.边界扫描的基础："></a>1.边界扫描的基础：</h2><p>   在芯片开始容纳更多复杂的组件（component），并且组件内部本身开始变得更加复杂时，采用片外（off-chip）的方法去测试芯片已经显得不实际。一个简单的解决思路是，探究出一套能单独测试每一个组件的方法，并且不会产生额外过多的测试成本（Test cost）。这个方法需要有几个特点：</p>
<p>   1）这个方法需要复用性，如果不同的组件都有自己独立的测试interface，那么测试将变得极为困难，所以最好最好需要每个组件都有一组类似的测试接口。</p>
<p>   2）随着测试越来越复杂，测试工程师希望能用一个program来使得测试自动化，因而测试过程能用一套类似的底层控制指令集合来控制实际的测试过程。</p>
<p>   围绕第一点，在1985年，设计工程师，芯片厂商和测试工程师门衍生出了一套通用测试的接口，JTAG （Joint Test Access Group), 这个group能够将测试的数据移入待测试的组件中来测试。这也是IEEE-1149.1这个标准的前身。当这个接口开始成为产业的一种趋势和标准后，ATE （automatic testing equipment）的硬件发展和软件开发开始获得飞速的发展。</p>
<p><img src="https://github.com/xulixing/blog_images/raw/main/DFT/Boundary_scan/general_structure_of_BS1149.1.png" alt="general_structure_of_BS1149.1"></p>
<p>   从上图可以看出，这套协议核心是：用外部的，数量少的信号（Test Access Ports）去控制需要测试组件或者说core的边界的scan flopflops chain。利用这个chain，我们可以将需要的测试数据移入（shift in）和收集（shift out）相应的响应（response）。因而这个方法可以将待测试的core于片内邻近的core区分开，实现单独测试的需求。</p>
<p>   围绕第二点，BS-1149.1定义了几组指令集合，将会在第三节详细介绍。</p>
<h2 id="2-BS-1149-1-架构"><a href="#2-BS-1149-1-架构" class="headerlink" title="2. BS-1149.1 架构"></a>2. BS-1149.1 架构</h2><p>上图只展示scan register包围core的这一部分，这部分通常在结构上，我们抽象成BSC（Boundary Scan Cell）。关于如何通过通用的Test Access Port去控制BSC，还需要一个具体架构。</p>
<p><img src="https://github.com/xulixing/blog_images/raw/main/DFT/Boundary_scan/detailed_structure_of_BS1149.1.png" alt="detailed_structure_of_BS1149.1"></p>
<p>   首先我们关注一下几个Test Access Port：</p>
<p>   TDI (Test Data In) ，TDO (Test Data Out)，这两个port负责串行地输入，输出数据。</p>
<p>   TMS (Test Mode Select)：把数据传输放到特定的state下进行。</p>
<p>   TCLK (Test Clock) ：连接负责测试时钟信号。</p>
<p>   TRST (Test Reset)：这是一个optional的端口，连接的reset信号可将测试逻辑转变成noninvasive状态。</p>
<h3 id="2-1-寄存器"><a href="#2-1-寄存器" class="headerlink" title="2.1 寄存器"></a>2.1 寄存器</h3><p>   BS-1149.1 的寄存器主要分成数据寄存器和指令寄存器。</p>
<h4 id="2-1-1-指令寄存器（IR）"><a href="#2-1-1-指令寄存器（IR）" class="headerlink" title="2.1.1 指令寄存器（IR）"></a>2.1.1 指令寄存器（IR）</h4><pre><code>架构如下图，
</code></pre>
<p>   <img src="https://github.com/xulixing/blog_images/raw/main/DFT/Boundary_scan/Instruction_register_structure.png" alt="instruction_register_structure "></p>
<p>   由于整个测试过程中，测试的控制和进行都是依赖于指令，从信号完整性和可控制的角度上，我们需要先将数据registered。因而这个IR是两级Flipflop的一个硬件结构。当UpdateIR有效时，存在第一级Flipflop的instruction bit才会被传递到第二级Flipflop。<br>     MUX的并行输入里，Din输入的是一个capture指令，Sin（信号来自TDI或者上一模块输出）则输入的是一个shift信号。MUX的选择端，则是用一个ShiftIR信号来控制。MUX的输出的会被ClockIR信号来clocked将信号锁村在第一级Flipflop中。</p>
<h4 id="2-1-2-数据寄存器（DR）："><a href="#2-1-2-数据寄存器（DR）：" class="headerlink" title="2.1.2 数据寄存器（DR）："></a>2.1.2 数据寄存器（DR）：</h4><h5 id="2-1-2-1-Bypass-Register-（BYR）："><a href="#2-1-2-1-Bypass-Register-（BYR）：" class="headerlink" title="2.1.2.1 Bypass Register （BYR）："></a>2.1.2.1 Bypass Register （BYR）：</h5><p>   Bypass register是BS1149.1 协议中规定必须要存在的寄存器。利用这个bypass的特性还可以用来测试wrapper chain的一个完备性。当ShiftBY=1时，进入旁路模式，原本固定项连的拓扑结构被打破，我们遍可以控制到某一个core的输入和其响应的提前输出。</p>
<p>  <img src="https://github.com/xulixing/blog_images/raw/main/DFT/Boundary_scan/bypass_register_strucutre.png" alt="bypass_register_structure "><br>  <img src="https://github.com/xulixing/blog_images/raw/main/DFT/Boundary_scan/bypass_example.png" alt="bypass_example "><br>     如上例，我们若只是想测试到core2，可以bypass core1，bypass core3。</p>
<h5 id="2-1-2-2-Device-Identification-Register-（DIR）"><a href="#2-1-2-2-Device-Identification-Register-（DIR）" class="headerlink" title="2.1.2.2 Device Identification Register （DIR）"></a>2.1.2.2 Device Identification Register （DIR）</h5><p>   这是存放chip的ID的寄存器，我们可以通过分辨输出的数据的ID来判断我们是否访问到了正确的chip。debugger的工具能够根据ID来解码分析，我们具体使用到的test access port。</p>
<h5 id="2-1-2-3-Boundry-Scan-Register-（BSR）"><a href="#2-1-2-3-Boundry-Scan-Register-（BSR）" class="headerlink" title="2.1.2.3 Boundry Scan Register （BSR）"></a>2.1.2.3 Boundry Scan Register （BSR）</h5><p><img src="https://github.com/xulixing/blog_images/raw/main/DFT/Boundary_scan/Boundary_scan.png" alt="boundary_scan"><br> Boundary scan 能够通过BSR非常简单地解决掉单独core的测试。BSR意味着我们能够直接访问待测的core的边界以施行测试，节约了很多unnecessary的pattern bit，节省了测试费用。TMS，TCLK是并行连接到每一个chip，但是每一个待测的TDI，TDO是串行连接的。<strong>需要注意的是，不管是IP level or chiptop level 还是 package level 都有且只有一组TAP</strong>。<br>     BSR简单地插到core与core相连interconnect中去，使得core的输入和输出的可控制性和可观察性大大增加，具体的BSR的结构如下所示。当core处于功能模式（functional mode），这个register就应该是透明的，数据可以直接通过。<br><img src="https://github.com/xulixing/blog_images/raw/main/DFT/Boundary_scan/BSC.png" alt="BSC"><br><img src="https://github.com/xulixing/blog_images/raw/main/DFT/Boundary_scan/BSC_control.png" alt="BSC_control"></p>
<h5 id="2-1-2-4-User-Defined-Register-（UDR）"><a href="#2-1-2-4-User-Defined-Register-（UDR）" class="headerlink" title="2.1.2.4 User-Defined Register （UDR）"></a>2.1.2.4 User-Defined Register （UDR）</h5><p>​    update later</p>
<h3 id="2-2-TAP-Controller"><a href="#2-2-TAP-Controller" class="headerlink" title="2.2 TAP Controller"></a>2.2 TAP Controller</h3><h2 id="3-BS-1149-1-指令"><a href="#3-BS-1149-1-指令" class="headerlink" title="3. BS-1149.1 指令"></a>3. BS-1149.1 指令</h2><h2 id="4-边界扫描链结构"><a href="#4-边界扫描链结构" class="headerlink" title="4. 边界扫描链结构"></a>4. 边界扫描链结构</h2><h2 id="5-BSDL"><a href="#5-BSDL" class="headerlink" title="5.  BSDL"></a>5.  BSDL</h2><h2 id="Reference："><a href="#Reference：" class="headerlink" title="Reference："></a>Reference：</h2><ol>
<li><a href="https://vlsitutorials.com/">https://vlsitutorials.com/</a></li>
<li></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>5. Memory Hierachy</title>
    <url>/2021/11/07/computer-architecture/5.memory-hierachy/</url>
    <content><![CDATA[<h1 id="5-1-Memory-Hierachiy-Overview"><a href="#5-1-Memory-Hierachiy-Overview" class="headerlink" title="5.1  Memory Hierachiy Overview"></a>5.1  Memory Hierachiy Overview</h1><h2 id="5-1-1-Memory-development"><a href="#5-1-1-Memory-development" class="headerlink" title="5.1.1 Memory development"></a>5.1.1 Memory development</h2><p>Memory的性能发展并没有跟上CPU的性能，在计算机运算（CPU和Memory协同）内存的访问时间即数据的搬运时间过长，制约了计算性能。处理器的性能的发展速度远超于内存（如DRAM）的发展速度，这里有电路设计优化的因素，也有工艺的因素。处理器如果需要快速的处理数据，无论是指令还是数据，存储系统都应该能够快速供给。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/1.png" alt="Memory Wall"></p>
<p>一个很简单解决思路是：让memory系统层次化。靠近CPU的数据（即准备要用到的数据）使用访问速度快的存储类型如SRAM，稍远的则采用访问速度慢但容量大的DRAM。进一步，我们把计算机最常用的指令(如load，strore)和数据预存在更小的memory中，我们称其为cache 或高速缓存。存储在cache中的数据，可以被CPU快速访问。</p>
<p>Note：cache中可以存储指令和数据，在之后的介绍中仅描述为data。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/2.png" alt="Memory Hierachy"></p>
<h2 id="5-1-2-Cache-访问逻辑"><a href="#5-1-2-Cache-访问逻辑" class="headerlink" title="5.1.2 Cache 访问逻辑"></a>5.1.2 Cache 访问逻辑</h2><p>当CPU需要访问内存地址，即读对应的数据时，高速缓存的操作如下：</p>
<ol>
<li>先检查cache中有无匹配的地址: cache line/entry </li>
<li>假如内存的地址可以在cache里找到，cache只需要将数据传回，这个过程为Cache Hit</li>
<li>假如内存地址不在cache中找到，cache就会分配一个cache line给这个地址，处理器需要访问main memory，处理器往往需要停下来（Microprocessor stall）等到data从main memory中传回，这个过程为Cache Miss。以此类推，当Memory hierarchy更复杂时，也会有Main Memory Hit/ Miss。</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/3.png" alt="cache访问逻辑"></p>
<p>当CPU往内存写数据时，即写入对应数据时，高速缓存的操作如下：</p>
<ol>
<li>会先检查cache中有无这个地址，有则写入数据到对应的cache位置；</li>
<li>如果没有，则按照某种（policy）处理，这点在后边章节5.3.3细述。</li>
</ol>
<h1 id="5-2-Memory-System-Performance-Analysis"><a href="#5-2-Memory-System-Performance-Analysis" class="headerlink" title="5.2 Memory System Performance Analysis"></a>5.2 Memory System Performance Analysis</h1><p>Miss Rate/ Hit Rate：重要的指标来衡量存储层次的性能。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/4.png" alt="Hit&amp;Miss rate"></p>
<p>Average memory access time AMAT:平均内存访问时间：</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/5.png" alt="Average memory access time AMAT"></p>
<h1 id="5-3-Cache"><a href="#5-3-Cache" class="headerlink" title="5.3 Cache"></a>5.3 Cache</h1><p>紧接着根据以下三个问题来讨论cache的设计。</p>
<p>（1）具体什么样的data需要存放在cache？</p>
<p>（2）data如何被处理器发现？</p>
<p>（3）cache中的什么数据被新的数据取代，当cache写满时。</p>
<h2 id="5-3-1-具体什么样的data需要存放在cache？"><a href="#5-3-1-具体什么样的data需要存放在cache？" class="headerlink" title="5.3.1 具体什么样的data需要存放在cache？"></a>5.3.1 具体什么样的data需要存放在cache？</h2><p>Cache是无法聪明到可以预测接下来处理器会用到什么数据，所以cache只能去猜什么样的数据可能被需要，<strong>基于过去memory access pattern</strong>。特别地，cache使用的时间局域性（Temporal locality）和空间局域性（Spatial locality）以获得非常的低的miss rate。</p>
<h3 id="5-3-1-1-访存的局域特性"><a href="#5-3-1-1-访存的局域特性" class="headerlink" title="5.3.1.1 访存的局域特性"></a>5.3.1.1 访存的局域特性</h3><p>大多数程序并不会在所有时刻访问整个存储空间，访存位置出现局域性特点。</p>
<p><strong>A. 时间局域性 Temporal locality</strong> 指的是处理器很可能马上访问某一个数据，如果某一个数据被访问。因此当处理器从Main memory搬运特定数据到cache中，这个特定数据紧接着常用的数据也被搬运到cache中。</p>
<p>eg. 进入一个for循环，for内的数据比如i++，数据1和指令”+“会被反复用到。</p>
<p><strong>B. 空间局域性 Spatial locality</strong> 指的是处理器访问一个main memory的数据之后，那个特定数据所在memory位置的周围的数据很有可能被访问。因而附近的数据也会被一起搬运进入cache中。</p>
<p>eg. 比如矩阵乘法，比如图像边缘提取，附近的element会被一起计算。 </p>
<h3 id="5-3-1-2-cache存储的基本单位：Block-Cache-line-Cache-entry"><a href="#5-3-1-2-cache存储的基本单位：Block-Cache-line-Cache-entry" class="headerlink" title="5.3.1.2 cache存储的基本单位：Block/Cache line/Cache entry"></a>5.3.1.2 cache存储的基本单位：Block/Cache line/Cache entry</h3><p>通常处理器只会需求一个指令（对于MIPS系统则是一个word，32bit），但是cache的一个存储单位Block可以容纳不止一个word。因而当cache取特定指令（word）时候，往往连带其他指令（word）一起取回，存在block中。</p>
<p>总结以下，cache通常有以下几个parameter去描述：</p>
<ol>
<li>容量Capacity C：cache中能存有words的数量。</li>
<li>set（entry）S：set的数量。</li>
<li>block的大小 b：block size，number of words it contains</li>
<li>block的数量 B：number of blocks</li>
<li>关联度 N：degree of associativity</li>
</ol>
<h2 id="5-3-2-Data如何被处理器发现？"><a href="#5-3-2-Data如何被处理器发现？" class="headerlink" title="5.3.2 Data如何被处理器发现？"></a>5.3.2 Data如何被处理器发现？</h2><p>简单介绍一个cache的物理结构：一个cache分布在S个set中，（set可以粗略理解为行row），每一个set中容纳了一个或者多个block，每一个block容纳word的数量则取决于block size，b。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/6.png" alt="Mapping"></p>
<p>需要注意的是，当我们需要从Main memory取数据放入cache中时，cache的地址与Main memory地址有一种对应的位置，称为mapping。</p>
<p>特别地，每一个Main memory的地址仅仅对应到一个cache set地址。当一个cache set中含有多个block，则Main memory中数据可以进入指定set中的任意一个block中。按照一个cache set中的block 的数量，可以把cache分为几类。</p>
<ol>
<li>Directed mapped cache:<br>每一个cache set只含有一个block，因此cache set的数量S=B。一个Main memory的地址对应到唯一的cache set中唯一的block中，没有其他block可进入。</li>
<li>N-way set associative cache:<br>每一个cache set含有N个block，因此cache set的数量 S=B/N。一个Main memory 的地址对应到唯一的cache set，但是data可以进入特定set N block中任意一个block中。</li>
<li>A fully associative cache:<br>只有一个set，S=1，N=B。数据可以进入一个set，B个block中的任意一个。</li>
</ol>
<p>下面按照MIPS的memory系统为例子介绍cache三种架构。MIPS是一个32位系统，地址32位且byte-addressable，每一个地址包含4个byte。下面我们以cache capacity = C =8 words 作为例子讨论。</p>
<h3 id="5-3-2-1-Direct-mapped-cache"><a href="#5-3-2-1-Direct-mapped-cache" class="headerlink" title="5.3.2.1 Direct mapped cache"></a>5.3.2.1 Direct mapped cache</h3><p>首先需要知道direct mapped cache的mapping，左边为main memory 的地址，右边为cache的结构。右边cache的结构为direct mapped cache，一行有一个block，一个block存一个word。左边Main memory每个address存一个byte，0x0-0x3位置存在Set0，0x4-0x7位置存在Set1，以此类推，直到0x20-0x23位置又存回Set0中，以此循环。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/7.png" alt="Mapping"></p>
<p>回到5.3.2节我们需要讨论的东西，如何从cache address找到Main memory的数据？这就需要知道Main memory的地址如何对应到cache，这与memory的地址相关。对于地址如0xFFFFFFE4，32位可以分为byte offset，index（set bit），tag bit等。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/8.png" alt="Memory Adress 组成"></p>
<p>Byte offset：两位表示选中cache line的4个byte中选1个byte；</p>
<p>Index/Set offset：表示需要选中cache set的地址/行数；</p>
<p>Tag bit：剩下的bits在offset和set bit数量被决定，tag bit用来区分memory&amp;cache的mapping。</p>
<p>tag bit的内容也存在cache中。cache中可能还存有V（valid）和D（Dirty）bit。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/9.png" alt="Cache line 组成"></p>
<p>上图则表明了mapping的细节，set bit选 cache set，tag bit比较，valid有效时，生成hit信号。</p>
<p>Valid bit：cache set用这个valid bit表明这个set保存的data是否是有效的数据。valid=1，内容是有效的；valid=0，内容是无效的；当两个最近需要访问的地址map到了同一个cache block，这就是一个conflict发生了，所以最近的地址会驱逐前一个地址。</p>
<p>总结这种directed mapping的方式：</p>
<p>优点：设计简单，造价低，搜索速度快（几乎不用搜索） </p>
<p>缺点：因为序号index的共享度高，hit rate低。</p>
<h3 id="5-3-2-2-Multi-way-set-associative-cache"><a href="#5-3-2-2-Multi-way-set-associative-cache" class="headerlink" title="5.3.2.2 Multi-way set associative cache"></a>5.3.2.2 Multi-way set associative cache</h3><p>N-way set associative cache通过在一个set中提供N blocks，可以显著减少数据的conflict。N就被称为degree of associativity 相关度。C=8 word，N=2 way，S=4 set。对比上面的cache结构，log2(4)=2，则需要2个而不是3个select bit。tag bit则是28 bit而不是27bit。mapping的外围电路则是用到两个比较器，两个valid信号。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/10.png" alt="Multi-way set associative cache"></p>
<p>这类Set associative cache generlly有更低的miss rate相比于direct mapped cache（在相同的capacity的基础上）因为他们有更少的conflicts。但是这类set associativity cache通常会更慢和某种程度上更贵因为需要在output stage建立multiplexer和额外的比较器。</p>
<p>还值得注意的是：Multi-way的cache结构中，每一个cache set会有多组tag和valid bit。因此当N数量增加时，cache占用的总存储面积是上升的（容量C一定情况下）。</p>
<p>还有一个重要的事情是，在N-way已经满了而要写入数据时，哪一个数据需要被取代。这点将在5.3.3节讨论。Set associative cache常常被用作商业用途。</p>
<h3 id="5-3-2-3-Fully-associative-cache"><a href="#5-3-2-3-Fully-associative-cache" class="headerlink" title="5.3.2.3 Fully associative cache"></a>5.3.2.3 Fully associative cache</h3><p>一个Fully associative cache涵盖一个single set，但是有B个ways，B是block数量。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/11.png" alt="Fully associative cache"></p>
<p>这种cache类型相比于上述两种类型，有着最小的conflict misses rate（当cache容量一定时）缺点也明显，他需要极其多的硬件资源，such as tag bit comparators and mulitiplexers。</p>
<h3 id="5-3-2-4-Consideration-Block-size，b"><a href="#5-3-2-4-Consideration-Block-size，b" class="headerlink" title="5.3.2.4 Consideration: Block size，b"></a>5.3.2.4 Consideration: Block size，b</h3><p>我们再考虑一个重要的参数，block size，一个block中可以容纳超过一个word，超过一个word长度，因此可以充分利用到时间局域性和空间局域性。在一个word被取入cache block时，相邻的word也被一起存入cache block。<strong>但对于miss rate来说，增加block size的方法并不一定能够一定减少miss rate。</strong>这是因为当cache 容量一定的情况下，增加block size意味着block set的数量更小，单个block set map到的memory地址数量更多，miss rate还可能增加。</p>
<p>额外的，这增加了一个cache block的写入时间，因为写入的word数量增加。因此一旦发生了miss，从main memory进行搬运时，miss penalty会非常大。若想要降低miss penality则需要进一步层次化memory，如使用多级缓存结构。</p>
<p>结构上需要添加，block offset进行数据的选择。</p>
<p>现阶段，商用的cache架构还是会采用大的block size。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/12.png" alt="Block size 的影响"></p>
<p>总结一下三种cache type：</p>
<p>Increasing the associativity, N, usually reduces the miss rate caused by conflicts. But higher associativity requires more tag comparators. Increasing the block size, b, takes advantage of spatial locality to reduce the miss rate. However, it decreases the number of sets in a fixed sized cache and therefore could lead to more conflicts. It also increases the miss penalty.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/13.png" alt="三种cache类型的总结"></p>
<h2 id="5-3-3-Cache中的什么数据被新的数据取代"><a href="#5-3-3-Cache中的什么数据被新的数据取代" class="headerlink" title="5.3.3 Cache中的什么数据被新的数据取代?"></a>5.3.3 Cache中的什么数据被新的数据取代?</h2><p>首先引入一个概念：高速缓存的缺失，它指的是所访问的内存地址还没有预取到cache中。当发生缺失时候，则需要讲内存的数据取出放入cache中，当cache中有数据时，就需要进行替换。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/14.png" alt="三种cache类型的总结"></p>
<p>数据的替换策略与映射方式相关：</p>
<ol>
<li>对于direct mapped cache每一个地址对应到唯一block set，所以这个block中内容就是victim；</li>
<li>对于N-way set associative cache，如果set is full，则需要按照一定的规则来驱逐（evit）特定的block，被替换的block成为victim。</li>
<li>对于full associative cache，如果整个set都满了，就需要替换。</li>
</ol>
<p>以N-way set associative cache为例，替换策略有：</p>
<ol>
<li>轮换策略：先入先出，将一组各路乱换，算法简单，全局利用效率低。</li>
<li>LRU（Least recentyly used）policy：对各路进行位置进行排序，最常用的放到队列底；最不常用到的放到队列顶被替换。</li>
<li>随机策略：最容易实现。</li>
</ol>
<p>数据的替换策略与映射方式相关：</p>
<ol>
<li>对于direct mapped cache每一个地址对应到唯一block set，所以这个block中内容就是victim；</li>
<li>对于N-way set associative cache，如果set is full，则需要按照一定的规则来驱逐（evit）特定的block，被替换的block成为victim。</li>
<li>对于full associative cache，如果整个set都满了，就需要替换。</li>
</ol>
<p>以N-way set associative cache为例，替换策略有：</p>
<ol>
<li>轮换策略：先入先出，将一组各路乱换，算法简单，全局利用效率低。</li>
<li>LRU（Least recentyly used）policy：对各路进行位置进行排序，最常用的放到队列底；最不常用到的放到队列顶被替换。</li>
<li>随机策略：最容易实现。</li>
</ol>
<h2 id="5-3-4-Write-Policy"><a href="#5-3-4-Write-Policy" class="headerlink" title="5.3.4 Write Policy"></a>5.3.4 Write Policy</h2>]]></content>
      <categories>
        <category>Computer architecture</category>
      </categories>
      <tags>
        <tag>Computer architecture</tag>
      </tags>
  </entry>
  <entry>
    <title>Microarchitecture Part 1</title>
    <url>/2021/06/07/computer-architecture/microarchitecture-part-1/</url>
    <content><![CDATA[<p>Reference：</p>
<ol>
<li><em>Digital Design and Computer Architecture,</em> by David Harris, Sarah Harris</li>
<li><em>Introduction to Computing Systems</em>, by Yale N.Patt, Sanjay J. Patel</li>
</ol>
<h3 id="1-架构状态和指令集"><a href="#1-架构状态和指令集" class="headerlink" title="1. 架构状态和指令集"></a>1. 架构状态和指令集</h3><p>一个计算机架构是由它的指令集(instruction set)和架构状态(architectural state：The architectural state is the part of the CPU which holds the state of a process. )。MIPS处理器的架构状态包含程序计数器和32个寄存器。指令集决定了微架构的硬件层面的复杂程度。</p>
<h3 id="2-设计流程"><a href="#2-设计流程" class="headerlink" title="2. 设计流程"></a>2. 设计流程</h3><p>微架构可以分成两个相互作用的部分：数据通路(datapath)和控制通路(controlpath)。数据通路包括了内存，寄存器，ALU和分路选择器。控制通路则通过分路选择器（MUX）进行寄存器的enable控制，memory的读写以控制数据通路。</p>
<p>设计的过程可以分成几个步骤：</p>
<p>Step 1: 思考需要的硬件需要包含多少状态（多少级）存储元件。</p>
<p>Step 2: 在两级状态单元之间插入组合逻辑电路以计算next state。</p>
<p>Step 3: 通常会将架构的memory拆成两部分，一部分存储指令，另一部分存储数据。</p>
<h4 id="2-1-Case-study：MIPS-Micropossessor"><a href="#2-1-Case-study：MIPS-Micropossessor" class="headerlink" title="2.1 Case study：MIPS Micropossessor"></a>2.1 Case study：MIPS Micropossessor</h4><p>存储元件：存储元件通常还需要reset信号。</p>
<p>Note：1. instruction mem模块无clk，说明只要地址A改变，RD就会在一个短暂的组合逻辑delay后读出新的指令。2. 其余三个存储元件都是在clk的节拍下进行数据刷新，从时序的角度（寄存器的要求），地址和数据需要在时钟上升沿来之前保持一个setup time，在时钟上升沿来之后保持一个holding time。</p>
<p>The state of the system is changed only at the clock edge. The address, data, and write enable must setup sometime before the clock edge and must remain stable until a hold time after the clock edge.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%201/1.png" alt="components"></p>
<h3 id="3-MIPS-架构"><a href="#3-MIPS-架构" class="headerlink" title="3  MIPS 架构"></a>3  MIPS 架构</h3><p>我们接下来会讨论三种MIPS架构：单周期，多周期和流水线的架构。这三种结构的不同点在于状态存储单元的连接和非架构状态的数量不相同。</p>
<ol>
<li><p>单周期微处理器：处理整一个整理在一个周期。</p>
<p> 特点：控制单元简单，不需要任何的非架构状态。但微处理器的周期时间被最慢的指令所限制。</p>
</li>
<li><p>多周期微处理器：处理一条指令用一系列短周期。简单的指令相比于复杂的指令执行更少的周期。多周期的微处理器通过重复使用昂贵的硬件资源如加法器和内存，以减少硬件cost。（adder可能在多个周期以不同用途被调用，多周期微处理器通过添加几个非架构寄存器来保存中间结果）。</p>
<p> 多周期微处理器一次指处理一个指令，一个指令会花费多个时钟周期。</p>
</li>
<li><p>流水线微处理器：将流水线应用在单周期微处理器架构上。</p>
<p> 特点：可以同时处理多条指令，极大提高系统的吞吐量。流水线则对控制通路的要求更高，需要昂贵的额外的MUX和非架构流水线寄存器。</p>
</li>
</ol>
<h3 id="4-Perfomance-analysis"><a href="#4-Perfomance-analysis" class="headerlink" title="4 Perfomance analysis"></a>4 Perfomance analysis</h3><p>微处理器的性能用执行特点程序（或程序集）所以花费时间而定。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%201/2.png" alt="execution time"></p>
<ol>
<li>instructions: 取决与处理器架构和执行的程序的内容。某些架构下有复杂的指令因而在每个指令可以做更多的事情，但是有种复杂的处理器架构意味着在硬件上更加复杂，往往执行得更慢。（在此处默认执行同一套程序）</li>
<li>CPI：不同的微处理器架构有不同CPIs。CPI与处理器架构，存储器架构相关。存储器的架构会对CPI产生显著的影响。</li>
<li>Tc：处理器能运行的最高频率取决于关键路径上的delay和寄存器时序要求。事实上，由于工艺节点的进步，尽管微架构和逻辑不变处理器也能运行在更高的频率上。</li>
</ol>
]]></content>
      <categories>
        <category>Computer architecture</category>
        <category>Microarchitecture</category>
      </categories>
      <tags>
        <tag>Computer architecture</tag>
        <tag>Microarchitecture</tag>
      </tags>
  </entry>
  <entry>
    <title>Microarchitecture Part 2</title>
    <url>/2021/06/07/computer-architecture/microarchitecture-part-2/</url>
    <content><![CDATA[<p>Reference：</p>
<ol>
<li><em>Digital Design and Computer Architecture,</em> by David Harris, Sarah Harris</li>
<li><em>Introduction to Computing Systems</em>, by Yale N.Patt, Sanjay J. Patel</li>
</ol>
<h2 id="5-Singlecycle-Processor-单周期处理器"><a href="#5-Singlecycle-Processor-单周期处理器" class="headerlink" title="5. Singlecycle Processor 单周期处理器"></a>5. Singlecycle Processor 单周期处理器</h2><p>通过连接存储单元来建立组合逻辑电路的数据通路。控制通路（组合逻辑电路）可以决定控制信号。</p>
<p>Overview: We begin constructing the datapath by connecting the state elements with combinational logic that can execute the various instructions. Control signals determine which specific instruction is carried out by the datapath at any given time.</p>
<h3 id="5-1-Datapath-数据通路"><a href="#5-1-Datapath-数据通路" class="headerlink" title="5.1 Datapath 数据通路"></a>5.1 Datapath 数据通路</h3><h4 id="5-1-1-Step-1"><a href="#5-1-1-Step-1" class="headerlink" title="5.1.1 Step 1"></a>5.1.1 Step 1</h4><p>读指令：PC (Program counter) 寄存器包含需要处理的指令地址。</p>
<p>The program counter (PC) register contains the address of the instruction to execute</p>
<p>（灰色表示先前讨论过的state elements，黑色表示数据通路）</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/1.png" alt="PC"></p>
<p>处理器的具体行为取决于具体的取出的指令，我们先考虑lw指令。</p>
<p>The processor’s actions depend on the specific instruction that was fetched. First we will work out the datapath connections for the lw instruction.</p>
<h4 id="5-1-2-Step-2"><a href="#5-1-2-Step-2" class="headerlink" title="5.1.2 Step 2"></a>5.1.2 Step 2</h4><p>对于lw指令，这一步需要做的是读base address 和 offset address。base地址对应指令中rs的部分，即 Instr25:21的部分。offset对应Instr15:0。</p>
<p>For a lw instruction, the next step is to read the source register containing the base address &amp; offset address. This register is specified in the rs field of the instruction, Instr25:21. The offset is stored in the immediate field of the instruction, Instr15:0.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/2.png" alt="sign拓展"></p>
<p>由于十六位的地址可能是正数或者负数，必须要通过符号拓展成32位。</p>
<p>Because the 16-bit immedi- ate might be either positive or negative, it must be sign-extended to 32 bits</p>
<p>符号位拓展就是简单得将MSB（符号位）在高位复制拓展。</p>
<p>sign extension simply copies the sign bit (most significant bit) of a short input into all of the upper bits of the longer output.</p>
<h4 id="5-1-3-Step-3"><a href="#5-1-3-Step-3" class="headerlink" title="5.1.3 Step 3"></a>5.1.3 Step 3</h4><p>-Combinational calculation 组合逻辑计算</p>
<p>处理器需要将基地址（从寄存器中取）和偏移地址（拓展后）相加。两者通过一个三位ALU控制信号的控制下相加，产生ALUresult和zero信号，Zero 来表示结果是否为0。ALU结果送入数据存储器作为load指令的最终地址。</p>
<p>The processor must add the base address to the offset to find the address to read from memory. The 3-bit <em>ALUControl</em> signal specifies the operation. The ALU generates a 32-bit <em>ALUResult</em> and a <em>Zero</em> flag, that indicates whether <em>ALUResult</em> is 0. ALUResult is sent to the data memory as the address for the load instruction</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/3.png" alt="组合逻辑电路"></p>
<h4 id="5-1-4-Step-4"><a href="#5-1-4-Step-4" class="headerlink" title="5.1.4 Step 4"></a>5.1.4 Step 4</h4><ul>
<li>Mem reading / Mem 读取</li>
</ul>
<p>ALU的结果会作为Data memory的地址，经过一个时钟节拍后数据输出到 ReadData 总线写入目标寄存器中。具体目标寄存器对应地址在指令的rt部分即 Instr20:16的部分。黑线表示的是地址/数据。</p>
<p>The data is read from the data memory onto the ReadData bus, then written back to the destination register in the register file at the end of the cycle. The destination register for the lw instruction is specified in the rt field, Instr20:16.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/4.png" alt="Mem读取"></p>
<h4 id="5-1-5-Step-5"><a href="#5-1-5-Step-5" class="headerlink" title="5.1.5 Step 5"></a>5.1.5 Step 5</h4><ul>
<li>Write Back 写回</li>
</ul>
<p>RegWrite连接在使能信号，数据和地址和使能信号准备好后，在下一个周期CLK上升沿时候写入register中。上图蓝色部分。</p>
<p>RegWrite is connected to the port 3 write enable input, WE3.The write takes place on the rising edge of the clock at the end of the cycle.</p>
<p>-Determine address of next instruction for PC //取下一条指令的PC加法</p>
<p>Instructions mem是byte accessable。MIPS的32位指令包含4个byte。因而取下一个指令时候需要将PC+。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/5.png" alt="PC加法"></p>
<p>-Next, let us extend the datapath to also handle the sw instruction.接下来我们focus在sw(store word)指令的数据通路</p>
<p>sw也是需要基地址+偏移来确定mem的地址。不同点在于sw是写入mem而不是读取mem。因而在ALU计算出mem地址后，写入mem的data也需要准备好。因而在取基地址时候，也同时完成了从寄存器取数据。寄存器对应的地址在Instr20:16。使能信号为MemWrite。</p>
<p>the sw instruction reads a base address from port 1 of the register and sign-extends an immediate. The ALU adds the base address to the immediate to find the memory address. All of these func- tions are already supported by the datapath. The register is specified in the rt field, Instr20:16.  Enable signal is MemWrite.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/6.png" alt="地址写入"></p>
<p>-Next, consider extending the datapath to handle the R-type instructions 接下来我们考虑拓展数据通路到能处理R型指令。</p>
<p>加，减，或，比较。这些指令都是会用到从寄存器组中取数据并且在ALU中计算最后写回到寄存器组中。不同在于进行的是不同ALU操作。因此只需要添加不同的ALU硬件资源，使用不同ALU控制信号。</p>
<p>Add, sub, and, or, and slt. All of these instructions read two registers from the register file, perform some ALU operation on them, and write the result back to a third register file. They differ only in the specific ALU operation. Hence, they can all be handled with the same hardware, using different ALUControl signals.</p>
<p>增加MUX作为input的选择可以有效增加数据通路的处理能力。</p>
<p>This principle of enhancing the datapath’s capabilities by adding a multiplexer to choose inputs from several possibilities is extremely useful</p>
<p>如下，增加三个MUX来区分是lw&amp;sw还是R-type指令。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/7.png" alt="MUX&amp;WB"></p>
<p>branch 跳转指令</p>
<p>核心：增加一个MUX做选择，MUX的输入为正常变化的PC和branch后的PC，ALU返回是否需要跳转的选择信号。<br><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/8.png" alt="地址偏移量相加获得新地址"></p>
<h3 id="5-2-Control-path-控制通路"><a href="#5-2-Control-path-控制通路" class="headerlink" title="5.2 Control path 控制通路"></a>5.2 Control path 控制通路</h3><p>控制（译码）部分需要在取指完成之后，对指令opcode和funct（R-type的指令的opcode为0）进行译码以决定后面的数据如何执行。各个存储元件的使能信号，MUX的选通信号都要在译码控制单元的控制下执行。ALU使能的宽度（图中是三位）如果需要执行的指令集越多，ALU使能选通信号会更加复杂。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/9.png" alt="控制通路"></p>
<p>对于每一个指令，控制信号的真值表可以列出：</p>
<p>由于sw，beg不需要写回因而选通信号X表示dont care，方便组合逻辑电路的设计，使用*可以节省组合逻辑的面积和规模。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/10.png" alt="控制信号真值表"></p>
<h3 id="5-3-Performance-evaluation-性能的考量"><a href="#5-3-Performance-evaluation-性能的考量" class="headerlink" title="5.3 Performance evaluation // 性能的考量"></a>5.3 Performance evaluation // 性能的考量</h3><p>一个执行周期只执行一个周期，因此CPI=1。关键路径需要考虑lw load word取指到写回整个流程。</p>
<p>Each instruction in the single-cycle processor takes one clock cycle, so the CPI is 1. lw instruction provides the critical delay for accessing to the ALU, memory, and register file which are substantially slower than other operations.</p>
<h3 id="5-4-Comments"><a href="#5-4-Comments" class="headerlink" title="5.4 Comments"></a>5.4 Comments</h3><p>单周期微控制器有着三个主要的缺点：</p>
<p>The single-cycle processor has three primary weaknesses</p>
<ol>
<li><p>它要求的一个周期以维持最慢的一条指令lw而其他的质量都比它快。</p>
<p> First, it requires a clock cycle long enough to support the slowest instruction (lw), even though most instructions are faster.</p>
</li>
<li><p>过程中用到了三个加法器：ALU中和PC中两个，加法器在面积上昂贵，尤其是对于高速加法器。</p>
<p> Second, it requires three adders (one in the ALU and two for the PC logic); adders are relatively expensive circuits, especially if they must be fast.</p>
</li>
<li><p>它将指令存储器和数据存储器分离开。</p>
<p> Third, it has sepa- rate instruction and data memories, which may not be realistic. Most computers have a single large memory that holds both instructions and data and that can be read and written.</p>
</li>
</ol>
<h2 id="6-Multicycle-Processor-多周期微处理器"><a href="#6-Multicycle-Processor-多周期微处理器" class="headerlink" title="6. Multicycle Processor 多周期微处理器"></a>6. Multicycle Processor 多周期微处理器</h2><p>多周期处理解决上述的问题通过把指令拆成几个步骤。不同的指令有不同数量的步骤，复杂的指令步骤更多，因而需要更多时间完成。</p>
<p>The multicycle processor addresses these weaknesses by breaking an instruction into multiple shorter steps. Different instructions use different numbers of steps, so simpler instructions can complete faster than more complex ones.</p>
]]></content>
      <categories>
        <category>Computer architecture</category>
        <category>Microarchitecture</category>
      </categories>
      <tags>
        <tag>Computer architecture</tag>
        <tag>Microarchitecture</tag>
      </tags>
  </entry>
  <entry>
    <title>Microarchitecture Part 3</title>
    <url>/2021/06/07/computer-architecture/microarchitecture-part-3/</url>
    <content><![CDATA[<p>Reference：</p>
<ol>
<li><em>Digital Design and Computer Architecture,</em> by David Harris, Sarah Harris</li>
<li><em>Introduction to Computing Systems</em>, by Yale N.Patt, Sanjay J. Patel</li>
</ol>
<h2 id="7-Pipeline-Processor-流水线处理器"><a href="#7-Pipeline-Processor-流水线处理器" class="headerlink" title="7. Pipeline Processor 流水线处理器"></a>7. Pipeline Processor 流水线处理器</h2><p>流水线处理器可以通过分割单周期处理成五个部分。因此最高可以有五条指令一起执行。流水线可以有效地提高吞吐量。</p>
<p>We design a pipelined processor by subdividing the single-cycle processor into five pipeline stages. Thus, five instructions can execute simultaneously, one in each stage.</p>
<p>流水线从时间的角度充分利用了硬件资源。<br><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%203/1.png" alt="流水线时间角度上硬件资源"></p>
<h3 id="7-1-Datapath-数据通路"><a href="#7-1-Datapath-数据通路" class="headerlink" title="7.1 Datapath 数据通路"></a>7.1 Datapath 数据通路</h3><p>读写内存和寄存器组和使用ALU通常是处理的最大delay的部分。五级流水线的每一级都涵盖了一部分这些高延迟部分。具体得，我们可以分成取指IF，译码DE，运算EX，读写内存MEM，写回WB五个部分。</p>
<p>Reading and writing the memory and register file and using the ALU typically constitute the biggest delays in the processor. We choose five pipeline stages so that each stage involves exactly one of these slow steps. Specifically, we call the five stages Fetch(IF), Decode(DE), Execute(EX), Memory(MEM), and Writeback(WB).</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%203/2.png" alt="错误5-stage"></p>
<p>简单得增加几级reg在组合逻辑电路和读写存储单元之间会导致一些问题，上图便有一处错误！对于一些指令数据/地址需要提前到达，会有时序上的问题</p>
<p>One of the subtle but critical issues in pipelining is that all signals associated with a particular instruction must advance through the pipeline in unison</p>
<p>错误在于寄存器组的写逻辑上。寄存器在流水线中是在DE中读取数据，WB中回写数据。然而在回写的地址在DE准备好，而不是WB。</p>
<p>The error is in the register file write logic, The register file is peculiar because it is read in the Decode stage and written in the Writeback stage. And the correct address is already covered by other instructions when it comes to writeback stage.</p>
<p>这个错误可以简单通过下图修改，将正确的地址一起传递到WB再写回，因此这个地址和WB回写的数据是逻辑上同步的。</p>
<p>The WriteReg signal is now pipelined along through the Memory and Writeback stages, so it remains in sync with the rest of the instruction. WriteRegW and ResultW are fed back together to the register file in the Writeback stage.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%203/3.png" alt="正确5-stage"></p>
<p>事实上，流水线的设计关键难点在于处理hazards，处理指令执行的顺序。这个部分会在下面单独讨论。</p>
<p>A central challenge in pipelined systems is handling hazards that occur when the results of one instruction are needed by a subsequent instruction before the former instruction has completed. This section would be discussed sepearately later.</p>
<h3 id="7-2-Pipelined-Control-流水线控制"><a href="#7-2-Pipelined-Control-流水线控制" class="headerlink" title="7.2 Pipelined Control 流水线控制"></a>7.2 Pipelined Control 流水线控制</h3><p>通过取指后的opcode和funct译码控制存储的使能信号和MUX的选通信号。<br><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%203/4.png" alt="正确5-stage"></p>
<h3 id="7-3-Hazard"><a href="#7-3-Hazard" class="headerlink" title="7.3 Hazard"></a>7.3 Hazard</h3><p>在流水线系统中，多个指令在时间上同时被执行。当一条指令的的执行依赖于另一条指令完成的结果，则hazard发生。</p>
<p>When one instruction is dependent on the results of another that has not yet completed, a hazard occurs.</p>
<p>RAW(Read after write) hazard：下图表示hazard发生流水线写入寄存器组，如果接下来的两条指令读取寄存器时</p>
<p>RAW(Read after write) hazard：The diagram shows that hazards may occur in this pipeline when an instruction writes a register and either of the two subsequent instructions read that register.<br><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%203/5.png" alt="hazard"></p>
<p>通常来说如果遇到RAW hazard 最直白的解决方法就是流水线停下来等到hazard解决。仔细观察上述指令，我们可以发现：Add在EX时候在ALU已经完成了计算，在MEM级不需要任何操作。空等了一个周期才WB。可以通过提前向前传递ALU的结果来提前WB，减少流水线放慢的效率。</p>
<p>On closer inspection, however, observe that the sum from the add instruction is computed by the ALU in cycle 3 and is not strictly needed by the and instruction until the ALU uses it in cycle 4. In principle, we should be able to forward the result from one instruction to the next to resolve the RAW hazard without slowing down the pipeline.</p>
<p>Hazards 可以分成data hazard 和 control hazard。data hazard 发生在指令尝试读取一个寄存器，但该寄存器还未被写回时。control hazard 发生在当跳转指令还没决定下一条该跳转到那一条指令时候，取指已经发生。</p>
<p>Hazards are classified as data hazards or control hazards. A data hazard occurs when an instruction tries to read a register that has not yet been written back by a previous instruction. A control hazard occurs when the decision of what instruction to fetch next has not been made by the time the fetch takes place.</p>
<p>A    Data Hazard</p>
<p>B)    Control Hazard</p>
<p>C)    Branch Hazard</p>
]]></content>
      <categories>
        <category>Computer architecture</category>
        <category>Microarchitecture</category>
      </categories>
      <tags>
        <tag>Computer architecture</tag>
        <tag>Microarchitecture</tag>
      </tags>
  </entry>
  <entry>
    <title>Clock Domain Crossing (CDC) Part 1</title>
    <url>/2021/05/29/cdc/cdc-1/</url>
    <content><![CDATA[<p>Reference：</p>
<ol>
<li><p>《The Study of Synchronizer Design in Asynchronous Clock Domain System》-蒲田</p>
</li>
<li><p>《Clock Domain Crossing (CDC) Design &amp; Verification Techniques Using SystemVerilog》-Clifford E. Cummings</p>
</li>
</ol>
<h3 id="1-Metastability"><a href="#1-Metastability" class="headerlink" title="1. Metastability:"></a>1. Metastability:</h3><p>亚稳态指信号在一段时间内不再稳定在0或者1，原因在于存储元件并非理想元件，对于寄存器信号需要在时钟边沿前后保持不变（setup&amp;holding约束），否则可能产生不稳定的输出。在多时钟域设计中，亚稳态不能被避免但有害效应可以被中和抵消。</p>
<h4 id="1-1-Synchronization-failure"><a href="#1-1-Synchronization-failure" class="headerlink" title="1.1 Synchronization failure"></a>1.1 Synchronization failure</h4><p>下图展示两级FF，但是两级的CLK不同步，第二级FF在第一级输出未达到稳定时进行了采样，产生synchronization failure. 如下图，采样信号无法在bclk的下一个上升沿保持稳定，亚稳态会被传递。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_1/1.png" alt="同步错误"></p>
<p>“When sampling a changing data signal with a clock … the order of the events determines the outcome. The smaller the time difference between the events, the longer it takes to determine which came first. When two events occur very close together, the decision process can take longer than the time allotted, and a synchronization failure occurs.”</p>
<h4 id="1-2-Consideration"><a href="#1-2-Consideration" class="headerlink" title="1.2 Consideration"></a>1.2 Consideration</h4><p>每一级的FF都要一个具体的setup time 和 hold time，即要求input的数据在clock 上升沿前保持一段时间（setup）和之后保持一段时间（hold）。对于一个具体的设计而言，这个时间窗口（亚稳态窗口）可以视为一个design parameter，当这个时间窗口输入数据发生变化，输出就可能产生亚稳态。</p>
<h4 id="1-3-MTBF-Mean-Time-Before-Failure"><a href="#1-3-MTBF-Mean-Time-Before-Failure" class="headerlink" title="1.3 MTBF (Mean Time Before Failure)"></a>1.3 MTBF (Mean Time Before Failure)</h4><p>对于大多数应用，尤其是跨时钟域计算MTBF（Mean Time Before Failure）非常重要。Failure指的是信号通过通过一个同步寄存器进入亚稳态，持续保持亚稳态直到被下一级寄存器采样。MTBF表示两个failure之间的时间（希望大到几天，几年）。</p>
<p>MTBF表示触发器采样失败的时间间隔。MTBF的计算公式如下：MTBF的数值越大越好；大MTBF表明潜在失效发生在更长的时间范围内；小的MTBF表明亚稳态更可能发生。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_1/2.png" alt="MTBF相关"></p>
<p>定量计算公式如下：<br><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_1/3.png" alt="MTBF定量计算公式"><br>其中：</p>
<ul>
<li>tr = 分辨时间（时钟沿开始）// resolution time (start from clk edge)</li>
<li>𝜏,𝑇0 = 触发器参数 // parameters releated to FF</li>
<li>𝑓 = 采样时钟频率 // sampling frequency</li>
<li>a = 异步事件触发频率 // synchronized events activated frequency</li>
</ul>
<p>对于一个典型的 0.25µm 工艺的 ASIC 库中的一个触发器，我们取如下的参数：tr = 2.3ns, τ = 0.31ns, T0 = 9.6as, f=100MHZ, a = 10MHZ, MTBF = <strong>2.01 days</strong></p>
<h4 id="1-4-Approaches-to-reduce-metastability"><a href="#1-4-Approaches-to-reduce-metastability" class="headerlink" title="1.4 Approaches to reduce metastability"></a>1.4 Approaches to reduce metastability</h4><p>从MTBF的角度，减少亚稳态的方法有以下几种</p>
<ol>
<li><p>使用同步器：也就是我们常用的2级或者多级FF打拍的方法;同步器后面会专门论述；</p>
</li>
<li><p>降低频率：如果能满足功能要求，那么降低频率能够减少亚稳态的产生;</p>
</li>
<li><p>避免变化过快或者过于频繁的信号进行跨时钟采样</p>
</li>
<li><p>采用更快的触发器：更快的触发器，也可以减少亚稳态的产生。</p>
</li>
</ol>
<h3 id="2-Synchronizers"><a href="#2-Synchronizers" class="headerlink" title="2. Synchronizers"></a>2. Synchronizers</h3><p>当信号跨时钟域时候，最容易忽视的一个问题是，这个信号需要每个时钟都被采样，不能漏掉每一个值吗？这是新手最容易忽视的一个问题。当考虑到信号穿过CDC边界时，</p>
<p>我们考虑两种情况：</p>
<ul>
<li>有一些信号不需要sample 可以miss </li>
</ul>
<p>// some signals are not required to be sampled and could be missed.</p>
<ul>
<li>每一个信号都需要被sample 并且跨CDC </li>
</ul>
<p>// every signals are required to be sampled.</p>
<p>在这两种情况下：CDC信号都需要某种形式的同步在接收时钟域内<br>In both of these scenarios, the CDC signals will require some form of <strong>synchronization</strong> into the receiving clock domain.</p>
<p>同步器：是采样一个异步时钟信号，并将其过渡成与一个在本地或者采样时钟的输出信号。“A synchronizer is a device that samples an asynchronous signal and outputs a version of the signal that has transitions synchronized to a local or sample clock”</p>
<h4 id="2-1-Two-flip-flop-synchronizer"><a href="#2-1-Two-flip-flop-synchronizer" class="headerlink" title="2.1 Two flip-flop synchronizer"></a>2.1 Two flip-flop synchronizer</h4><p>最简单和最常用的同步器，是两级FF同步器.</p>
<p>第一级FF采样一个异步信号，极端情况（采样一个变化信号）则第一级FF输出为亚稳态；保持一个时钟周期（亚稳态recover），信号被重新采样为有效的输出。</p>
<p>Note：双寄存器并不能消除亚稳态，它只是减少出现亚稳态的概率，减少到一个可以几乎忽略不计的程度。<br><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_1/4.png" alt="两级同步器"></p>
<p>在这个过程，需要保证的这个保持时间，否则会产生synchronization failure。 这个时间与输入信号的频率和同步FF的频率有关。这个时间为MTBF。</p>
<p>对于大多数同步应用，两级FF同步器已经足够移除所有亚稳态。</p>
<h4 id="2-3-Three-flip-flop-synchronizer"><a href="#2-3-Three-flip-flop-synchronizer" class="headerlink" title="2.3 Three flip-flop synchronizer"></a>2.3 Three flip-flop synchronizer</h4><p>对于一些极其高速的应用，MTBF在两级同步器之间太短。因此可以添加第三级FF以增加MTBF到一个满意的时间范围。<br><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_1/5.png" alt="三级同步器"></p>
]]></content>
  </entry>
  <entry>
    <title>Clock Domain Crossing (CDC) Part 2</title>
    <url>/2021/05/29/cdc/cdc-2/</url>
    <content><![CDATA[<p>Reference：<br>《Clock Domain Crossing (CDC) Design &amp; Verification Techniques Using SystemVerilog》    -    Clifford E. Cummings</p>
<h3 id="2-4-Synchronizing-signals-requirements"><a href="#2-4-Synchronizing-signals-requirements" class="headerlink" title="2.4 Synchronizing signals requirements:"></a>2.4 Synchronizing signals requirements:</h3><h4 id="2-4-1-Requirment-for-sending-signals"><a href="#2-4-1-Requirment-for-sending-signals" class="headerlink" title="2.4.1 Requirment for sending signals"></a>2.4.1 Requirment for sending signals</h4><p>在发射时钟域&amp;接受时钟域，发送信号需要被registered。</p>
<p>对同步过程很容易误解成，只需要接受时钟域同步即可。但对于发送时钟域，异步信号是需要提前存在register中，即发送域寄存器和接受域寄存器之间不再有组合逻辑电路。若有组合逻辑电路：接受域的输入信号adat会由于组合逻辑电路不同输入变化带来不同情况的延迟变化，逻辑值不同等情况，这增加潜在毛刺（或是震荡信号）的可能性，也增加了亚稳态的可能。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/1.png" alt="without registered"></p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/2.png" alt="with registered"></p>
<h4 id="2-4-2-requirement-for-reliability-of-signals"><a href="#2-4-2-requirement-for-reliability-of-signals" class="headerlink" title="2.4.2 requirement for reliability of signals"></a>2.4.2 requirement for reliability of signals</h4><p>对信号的可靠性的要求。用更快的时钟采样慢信号（通常是1.5倍以上相较于慢信号），满信号会被采样一次或者多次，通常来说同步慢信号不会产生很多问题。但慢时钟采快信号会带来问题。</p>
<p>The “three edge” requirement：”input data values must be stable for three destination clock edges” 输入数据值需要在三个目标时钟沿保持稳定，即1.5个时钟周期。</p>
<p>Problem A: Passing a fast CDC pulse</p>
<p>当CDC信号只有一个快时钟周期的宽度，那么CDC信号可能在两个慢时钟的上升沿之间变化，因而接受时钟域并没有采集到信号变化。<br><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/3.png" alt="传递一个高速CDC脉冲"></p>
<p>Problem B: Sampling a long CDC pulse - but not long enough</p>
<p>当CDC信号的宽度大概略大于一个慢时钟周期的宽度，那么CDC信号在绝大多数情况下能顺利通过。但是在下图非常罕见的情况，adat恰好横跨一个慢周期的上升沿，那么有可能违反第一个寄存器的setup time要求和第二个寄存器的hold time要求，输出为亚稳态。<br><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/4.png" alt="采样一个不够长的CDC脉冲"></p>
<p>当不允许采样过程中丢失采样点，通常来说有两种方法来解决：</p>
<ol>
<li>开环控制：用同步器对信号进行采样：</li>
</ol>
<p>保证CDC信号大概在采样时钟周期地1.5倍左右，如此信号在一个周期中会被至少采样一次。</p>
<p>优点：开环地控制信号长度，最快的发送方式，不需要发送信号返回的acknowlegment。</p>
<p>缺点：当参数变化时候，工程师可能很难在发现这个错误。这个问题可以通过SV的断言来判断信号是否满足了3edge要求。<br>This problem can be minimized by adding a SystemVerilog Assertion to the model to detect if the input pulse ever fails to exceed the “three edges” design requirement.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/5.png" alt="开环控制"></p>
<p>闭环控制：信号穿过CDC后返回一个acknowledgement反馈信号，自动延长快时钟域的信号<br>在发射时钟域添加一个使能信号。当接受时钟域接受到信号后，通过一个发射时钟域的两级同步器产生acknowledgement信号，数据再从adat进入，开始传入下一个数据。</p>
<p>缺点：整个过程延迟过长（两级同步器）</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/6.png" alt="闭环控制"></p>
<h2 id="3-Multiple-signals-between-clock-domains"><a href="#3-Multiple-signals-between-clock-domains" class="headerlink" title="3. Multiple signals between clock domains"></a>3. Multiple signals between clock domains</h2><p>当传输多位信号时，简单的同步器并不能保证数据的安全传输。多位信号的传输的问题在于信号在同步过程中，数据变化的偏移（skew）也可能被不同上升沿采样到。</p>
<p>为了应对多位CDC偏移采样的情况，主要有以下几种解决方案：</p>
<ul>
<li>尽可能让多位的CDC信号合成单bitCDC信号</li>
<li>Multi-cycle path formulation. 使用同步信号来保证CDC信号能通过</li>
<li>使用Gray code</li>
</ul>
<h3 id="3-1-控制信号多比特的同步"><a href="#3-1-控制信号多比特的同步" class="headerlink" title="3.1 控制信号多比特的同步"></a>3.1 控制信号多比特的同步</h3><h4 id="Problem-1：多个控制信号之间传输偏移"><a href="#Problem-1：多个控制信号之间传输偏移" class="headerlink" title="Problem 1：多个控制信号之间传输偏移"></a>Problem 1：多个控制信号之间传输偏移</h4><p>例如下面例子，当load信号和en信号同时在接收时钟域拉高，aq_load 和 aq_en才能同时被传输，才能实现load的操作。因而控制信号的skew可以导致两个控制信号的传输不同步，今儿导致后续接收时钟域的控制信号不同步。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/7.png" alt="多个控制信号"></p>
<h4 id="Solution-1：合并"><a href="#Solution-1：合并" class="headerlink" title="Solution 1：合并"></a>Solution 1：合并</h4><p>将两个控制信号合并成一个，控制信号之间就不存在同步问题。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/8.png" alt="合并"></p>
<h4 id="Problem-2-多个控制信号之间存在时钟相位差"><a href="#Problem-2-多个控制信号之间存在时钟相位差" class="headerlink" title="Problem 2: 多个控制信号之间存在时钟相位差"></a>Problem 2: 多个控制信号之间存在时钟相位差</h4><p>如果两个控制信号本身存在一定的时钟相位差，以满足一些逻辑或者数据传输的时序要求，那么在传输过程中（或者说在接收时钟域中），可能控制信号未被采集到。因而导致数据通路出问题</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/9.png" alt="时钟相位差"></p>
<h4 id="Solution-2：在接受域内产生控制信号"><a href="#Solution-2：在接受域内产生控制信号" class="headerlink" title="Solution 2：在接受域内产生控制信号"></a>Solution 2：在接受域内产生控制信号</h4><p>改进方法：只传输一个信号，另一个信号在同步时钟域中产生。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/10.png" alt="接受域产生控制信号"></p>
<h3 id="3-2-数据信号多比特的同步"><a href="#3-2-数据信号多比特的同步" class="headerlink" title="3.2 数据信号多比特的同步"></a>3.2 数据信号多比特的同步</h3><p>数据多位数据的传输对位间偏移敏感。下面例子展示了编码信号传播到接收时钟域，若偏移存在，可能导致接受时钟域产生完全错误的结果。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/11.png" alt="接受域产生控制信号"></p>
<p>解决数据同步方法主要有两种 </p>
<ol>
<li>Multi-cycle path formulation 多周期路径规划    </li>
<li>FIFO</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>DFT Introduction</title>
    <url>/2021/05/29/design-for-testability/dft-basic/</url>
    <content><![CDATA[<p>在芯片设计-制造流程结束之后，测试（testing）也在芯片领域里面有着极其重要的地位。这个过程中，操作面相的对象是实际生产完成的chip，目的上检测芯片的生产过程中，产生缺陷（defect）。和前端的设计/验证不同，测试并不是使用软件的方法（EDA工具）去发现并暴露错误，这个过程还是发生在tape-in。 </p>
<p>测试则是发生在tape-out之后，通过物理的测试机器（tester）去<strong>提供激励</strong>和<strong>收集响应</strong>来验证芯片中是否defect。笼统地来说，测试的角色则是，保证芯片（或者说产品）的正确性（correctness）和有效性（effectiveness）。</p>
<ol start="0">
<li>DFT需要解决掉的几件事情<ol>
<li>Fault model：我们需要测试到defect，但是这个defect是一个偏向于器件物理和材料的概念，我们需要能够统计和量化它。思路是建立fault model，电路中每个位置可能出现的defect抽象成一个fault，然后用fault的可测试性来描述对defect的测试能力。</li>
<li>Pattern generation：有了fault model之后，我们则将defect这一个物理概念转译为一个叫做fault的逻辑概念。但是这种fault大概率是处于电路内部，芯片tape-out之后我们只能从input&amp;output端口去观察芯片的行为，意味着我们要从input控制到它，并且这个fault能传递到output被观察到。那么这种特定的input，就被称之为测试向量test pattern或者test vector。产生test pattern的整个过程则称之为pattern generation。</li>
<li>Fault simulation：有了pattern，我们则理论上能够测试到特定的的fault。那么我们如何来描述测试向量的质量呢？即按照特定fault按照算法，产生的test pattern，是否在输入实际电路后也是能测试那个特定的fault？这里用到fault simulation。值得注意的是，在第2部，产生pattern时候我们通常会添加一些辅助硬件电路。因而实际上在考虑一些时序的corner的时，simulation会fail，因而实际上达不到允许的fault coverage。</li>
<li>ATE/BIST：通过了fault simulation的pattern，通常我们就认为是有效的pattern，那么这些pattern将如何输入到实际的芯片中去的呢？一种方法就是利用ATE（Automatic Test Equipment）直接打激励进入芯片。另一种则是利用BIST逻辑（Built-in—self-test）即pattern会通过BIST自己产生，输入到芯片，并且BIST会自动收集响应来判断是否是期望的响应。</li>
</ol>
</li>
</ol>
<ol>
<li><p>Fault Model<br> fault有不同的类型，用于区分不同的defect的类型。文章在这里做一个极其粗糙的简化，将fault简答地分成stuck-at fault和at-speed fault。在这里的简化，是为了略过对defect形成的不同的物理原因的讨论，抓住DFT关注和讨论的主线。</p>
<ol>
<li><p>功能相关: Stuck-at-fault (SAF)</p>
<p>Stuck-at是最</p>
</li>
<li><p>速度相关：At—speed-fault （ACF）</p>
</li>
</ol>
</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/DFT/1.fault_model%20%26%20failure_mechanisoms/1.png" alt="fault sites"></p>
<p>Notes: </p>
<p><strong>Mutiple SAT:</strong><br><strong>Multiple stuck-at faults are usually not considered in practice because of two reasons</strong></p>
<p><strong>– The number of multiple stuck-at faults in a circuit with k lines is 3^k-1, which is too large a number even for circuits of moderate size</strong></p>
<p>– <strong>Tests for single stuck-at faults are known to cover a very high percentage (greater than 99.6%) of multiple stuck-at faults when the circuit is large and has several outputs</strong></p>
<ol start="2">
<li>Stuck-open fault model (SOpF)</li>
</ol>
<p>Testing: need a sequential test vectors (tesing the transient from connect to disconnect)</p>
<ol start="3">
<li>Stuck-on fault model (SOnF): might contribute a directed path from vdd to ground.</li>
</ol>
<p>Testing: Iddq test, test the current whether is surficiently large.</p>
<ol start="4">
<li><p>Geometrical Fault Model: Bridging Faults (BFs) , get shorted for example.</p>
</li>
<li><p>Pattern-sensitive fault: changed by neightbor values. (DRAM)</p>
</li>
<li><p>Coupling fault: Between Cells (Victim and Aggressor)</p>
</li>
<li><p>Delay fault model: slow to propagate a 1 to 0 for example.$</p>
</li>
<li><p>Crosstalk defects: </p>
</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/DFT/1.fault_model%20%26%20failure_mechanisoms/2.png" alt="Crosstalk defects"></p>
<p>source from: tow parasitc capacitance between two signal nets.</p>
<pre><code>### * 1. 1. 1. 1. 1. 1. 1. 1. 1. &gt; &gt;         ``·![]()
</code></pre>
]]></content>
      <categories>
        <category>DFT</category>
      </categories>
      <tags>
        <tag>DFT</tag>
      </tags>
  </entry>
  <entry>
    <title>Efficient FSM coding in verilog</title>
    <url>/2021/04/05/fsm-coding/notes-fsm-coding/</url>
    <content><![CDATA[<p>Learning Source:《The Fundamentals of Efficient Synthesizable Finite State Machine Design using NC-Verilog and BuildGates》</p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract:"></a>Abstract:</h3><ol>
<li>Important techniques related to one and two always block styles to code FSMs with combinational outputs are given to show why using a two always block style is preferred. </li>
<li>An efficient Verilog-unique onehot FSM coding style is also shown. </li>
<li>Reasons and techniques for registering FSM outputs are also detailed.</li>
</ol>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction:"></a>1. Introduction:</h3><h4 id="Note-利用Always语句编写组合逻辑电路和时序逻辑电路。"><a href="#Note-利用Always语句编写组合逻辑电路和时序逻辑电路。" class="headerlink" title="Note: 利用Always语句编写组合逻辑电路和时序逻辑电路。"></a>Note: 利用Always语句编写组合逻辑电路和时序逻辑电路。</h4><ol>
<li><p>组合逻辑电路的always block编写严格（阻塞赋值），敏感列表内没有posedge or negedge这些verilog keyword！</p>
<blockquote>
<p>Combinational always blocks are always blocks that are used to code combinational logic functionality and are strictly coded using blocking assignments。</p>
</blockquote>
</li>
<li><p>时序电路always block（非阻塞赋值），有edge-based sensitivity list。</p>
</li>
</ol>
<h3 id="2-Mearly-and-moore-FSM"><a href="#2-Mearly-and-moore-FSM" class="headerlink" title="2. Mearly and moore FSM"></a>2. Mearly and moore FSM</h3><p><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/1.%20FSM%E7%B1%BB%E5%9E%8B.png" alt="Figure 1.FSM_type"></p>
<h3 id="3-Binary-or-Onehot-Encoded"><a href="#3-Binary-or-Onehot-Encoded" class="headerlink" title="3. Binary or Onehot Encoded?"></a>3. Binary or Onehot Encoded?</h3><ul>
<li><p>Binary-encode FSM 需要的位宽（FF的数量）仅是需要状态的log2（#states）</p>
<p>  优点：使用触发器的个数较少，节省资源。<br>  缺点：状态跳转时可能有多个bit错误，引起毛刺，造成逻辑错误。</p>
</li>
<li><p>One-hot encode FSM 需要的位宽（FF的数量）为需要的状态的数量。</p>
<p>  缺点：增加了触发器个数，寄存器资源利用效率低。<br>  优点：但是方便译码，有效化简组合逻辑电路</p>
</li>
</ul>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/2.%20code%20style.png" alt="Figure 2.编码方式"></p>
<p>Notes：</p>
<ol>
<li><p>FPGA推荐使用one-hot编码因为其内置有足够数量的FF，使用one-hot编码可以节省复杂的译码组合逻辑电路设计。</p>
<blockquote>
<p>FPGA vendors frequently recommend using a onehot state encoding style because flip-flops are plentiful in an FPGA and the combinational logic required to implement a onehot FSM design is typically smaller than most binary encoding styles.</p>
</blockquote>
</li>
<li><p>FPGA的性能与FPGA中组合逻辑电路的size的决定。实现同样的功能，onehot码的用到的组合逻辑电路面积更小，可以run faster。</p>
<blockquote>
<p>Since FPGA performance is typically related to the combinational logic size of the FPGA design, onehot FSMs typically run faster than a binary encoded FSM with larger combinational logic blocks</p>
</blockquote>
</li>
</ol>
<h3 id="4-FSM-Coding-Goals："><a href="#4-FSM-Coding-Goals：" class="headerlink" title="4. FSM Coding Goals："></a>4. FSM Coding Goals：</h3><ul>
<li>The FSM coding style should be easily modified to change state encodings and FSM styles.</li>
<li>The coding style should be compact.</li>
<li>The coding style should be easy to code and understand.</li>
<li>The coding style should facilitate debugging.</li>
<li>The coding style should yield efficient synthesis results.</li>
</ul>
<h3 id="5-Two-Always-Block-FSM-style-Good"><a href="#5-Two-Always-Block-FSM-style-Good" class="headerlink" title="5. Two Always Block FSM style (Good)"></a>5. Two Always Block FSM style (Good)</h3><h4 id="5-1-Exapmle-Code"><a href="#5-1-Exapmle-Code" class="headerlink" title="5.1 Exapmle_Code"></a>5.1 Exapmle_Code</h4><p>用两个always block编写，一个写时序逻辑，一个写组合逻辑。</p>
<p>Note：</p>
<ol>
<li>时序always block定义时序电路（状态转移），非阻塞赋值。</li>
<li>组合always block定义组合逻辑电路，敏感列表为输入，没有时钟clk和复位信号，使用阻塞赋值。</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/3.4states_FSM.png" alt="Figure 3.Four-states FSM"></p>
<p>Important notes:</p>
<ol>
<li><p>Parameter 定义state类型（binary还是onehot）和名称（state的名字）：方便修改，如果需要换coding style的话就只需要更改parameter的定义就行。</p>
</li>
<li><p>在输出赋值之后，再给state or next state赋值。</p>
<blockquote>
<p>Declarations are made for state and next (next state) after the parameter assignments.</p>
</blockquote>
</li>
<li><p>时序逻辑用非阻塞赋值。</p>
<blockquote>
<p>The sequential always block is coded using nonblocking assignments.</p>
</blockquote>
</li>
<li><p>组合逻辑电路的敏感列表有state，所有组合逻辑input变量。</p>
</li>
<li><p>组合逻辑电路always block中用阻塞赋值。</p>
</li>
<li><p><strong>The combinational always block has a default next state assignment at the top of the always block</strong></p>
</li>
<li><p>输出在case语句前被赋初值（default value）。优点在于：</p>
<p> A. case语句之后不需要再写default的情况，电路上消除了产生锁存器的可能。<br> B. 每一个case中只在输出变化赋新的值。从代码上，更容易观察到输出的变化，代码可读性增加。</p>
<blockquote>
<p>Default output assignments are made before coding the <strong>case</strong> statement (this eliminates latches and reduces the amount of code required to code the rest of the outputs in the <strong>case</strong> statement and highlights in the <strong>case</strong> statement exactly in which states the individual output(s) change)</p>
</blockquote>
</li>
<li><p>组合逻辑always block内的if-else 语句数量和 状态转移图STD的转移弧线数量一致。（输入的 !rst不算）</p>
<blockquote>
<p>The number of transition arcs between states in the FSM state diagram should equal the number of <strong>if</strong>-<strong>else</strong>-type statements in the combinational always block.</p>
</blockquote>
</li>
<li><p>方便查看，next的赋值都放在同一列。</p>
</li>
</ol>
<h4 id="5-2-Fear-of-transitions-to-erroneous-states"><a href="#5-2-Fear-of-transitions-to-erroneous-states" class="headerlink" title="5.2 Fear of transitions to erroneous states"></a>5.2 Fear of transitions to erroneous states</h4><p>一般来说，不会发生。</p>
<p>在一些极端情况下，系统要求更高的robertness：如alpha粒子，高能粒子等。系统的状态可能进入到一个错误状态！但是让state/next state寄存器回到想要的状态并不够！这是因为可能，剩下部分的硬件已经进入变化后的state的状态。</p>
<p>Possible bad situation：系统可能因此进入一个lockup状态，因为硬件正在等待一个不可能到来的状态转移信号。（如系统在启动后，由于高能粒子轰击，刚好回到启动state，但是外界不会再给启动的激励，因而系统会卡在此状态不动）</p>
<p>解决办法：需要一种设计，当state寄存器进入到错误状态时：不仅下一个时刻，state能自动回到正常状态，剩下的状态也会在下一个状态过渡时候reset！</p>
<h4 id="5-3-Making-default-next-equal-all-X’s-assignment"><a href="#5-3-Making-default-next-equal-all-X’s-assignment" class="headerlink" title="5.3 Making default next equal all X’s assignment"></a>5.3 Making default next equal all X’s assignment</h4><p>在组合逻辑always敏感列表后，直接对next进行赋初值X‘s，next会在之后的case中被赋初值。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/3.4states_FSM.png" alt="Figure 4.Four-states FSM"></p>
<p>如果我们给全X给next，如果某一状态转移可能没有在case语句中被描述到，state的预综合仿真模型会产生一个未知的输出的状态。这是一个有效debug FSM设计的方法。X在综合工具里认为是don’t care. </p>
<blockquote>
<p>By making a default next state assignment of X’s, pre-synthesis simulation models will cause the state machine outputs to go unknown if not all state transitions have been explicitly assigned in the case statement. This is a useful technique to debug state machine designs, plus the X’s will be treated as “don’t cares” by the synthesis tool.</p>
</blockquote>
<p><strong>不理解的问题：如果组合逻辑过于复杂？？？？如pcpu</strong></p>
<h3 id="6-One-Always-Block-FSM-style-Avoid"><a href="#6-One-Always-Block-FSM-style-Avoid" class="headerlink" title="6 One Always Block FSM style (Avoid)"></a>6 One Always Block FSM style (Avoid)</h3><h3 id="7-Onehot-FSM-Coding-style-Good-style"><a href="#7-Onehot-FSM-Coding-style-Good-style" class="headerlink" title="7 Onehot FSM Coding style. (Good style)"></a>7 Onehot FSM Coding style. (Good style)</h3><p>Onehot 编码与二进制编码的核心在于parameter不再代表state encoding，而是用来表示state向量的index。case的语句的比较则简化成单个bit的比较。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/4.%20onehot_coding.png" alt="Figure 5.Onehot FSM"></p>
<p>Onehot 编码与二进制编码的核心在于parameter不再代表state encoding，而是用来表示state向量的index。case的语句的比较则简化成单个bit的比较。</p>
<p>在case语句下，比较进入分支时，本身带有优先级（即从第一种情况到default），因而这本身综合器会综合一个组合逻辑的优先级编码器电路。由于onehot编码本身不存在优先级，每一个case在逻辑上是并行，这是作者唯一推荐使用full_case 和 parallel_case 语句（告诉仿真器 1. 已经穷尽了所有case，不要生成锁存器 2.消除优先级编码器电路）</p>
<p>This is the only coding style where I recommend using full_case and parallel_case statements. The parallel case statement tells the synthesis tool to not build a priority encoder even though in theory, more than one of the state bits could be set (as engineers, we know that this is a onehot FSM and that only one bit can be set so no priority encoder is required). The value of the full_case statement is still in question.</p>
<p>Note：多个输出onehot编码，优先编码器</p>
<blockquote>
<p><a href="http://www.cburch.com/logisim/docs/2.3.0/libs/plexers/priencod.html">http://www.cburch.com/logisim/docs/2.3.0/libs/plexers/priencod.html</a></p>
</blockquote>
<p>关于parallel_case和full_case的使用</p>
<blockquote>
<p><a href="https://blog.csdn.net/teenagerold/article/details/78022636?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-0&spm=1001.2101.3001.4242">https://blog.csdn.net/teenagerold/article/details/78022636?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-0&amp;spm=1001.2101.3001.4242</a></p>
</blockquote>
<blockquote>
<p><a href="https://blog.csdn.net/childbor/article/details/78633541?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-1&spm=1001.2101.3001.4242">https://blog.csdn.net/childbor/article/details/78633541?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-1&amp;spm=1001.2101.3001.4242</a></p>
</blockquote>
<h3 id="8-Registered-FSM-Output-Good-style"><a href="#8-Registered-FSM-Output-Good-style" class="headerlink" title="8 Registered FSM Output. (Good style)"></a>8 Registered FSM Output. (Good style)</h3><p>在输出级加一个register可以保证输出没有glitch，优化综合结果。</p>
<p>Registering the outputs of an FSM design insures that the outputs are <strong>glitch-free</strong> and frequently improves synthesis results by standardizing the output and input delay constraints of synthesized modules.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/5.registeredFSM.png" alt="Figure 6.Registered FSM"></p>
<h3 id="9-System-Verilog-Enhancement"><a href="#9-System-Verilog-Enhancement" class="headerlink" title="9 System Verilog Enhancement"></a>9 System Verilog Enhancement</h3>]]></content>
      <categories>
        <category>FSM_verilog</category>
      </categories>
      <tags>
        <tag>FSM</tag>
      </tags>
  </entry>
</search>
